<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Yuming Du">
<meta name="description" content="Yuming DU&#39;s home page">
<meta name="google-site-verification" content="X2QFrl-bPeg9AdlMt4VKT9v6MJUSTCf-SrY3CvKt4Zs" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Yuming DU&#39;s Homepage</title>
<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-159069803-1', 'auto');
ga('send', 'pageview');
</script>
<!-- End Google Analytics -->
<!--
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
-->
</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Yuming DU <font face="Arial">    杜禹明 </font></h1></div>

				<h3>Ph.D.</h3>
				<p>
					Email: <a href="mailto:dulucas24@gmail.com">dulucas24 AT gmail DOT com</a><br>
				</p>
				<p>
					<a href="https://github.com/dulucas"><img src="./pic/others/github_logo.png" height="30px"></a>&nbsp;&nbsp;
					<a href="https://scholar.google.com/citations?user=mLytdOoAAAAJ&hl=en"><img src="./pic/others/google_scholar_logo.png" height="30px"></a>&nbsp;&nbsp;
					<a href="https://twitter.com/yuming_du"><img src="./pic/others/twitter_logo.png" height="30px"></a>&nbsp;&nbsp;
				</p>
				</p>
			</td>
			<td>
				<img src="./pic/dym.jpg" border="0" width="220"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2>Biography </h2>
<p>
	Research Scientist at Meta.
	<br>
	<br>
	Ph.D. from ENPC, supervisor: <a href="https://vincentlepetit.github.io/">Prof. Vincent Lepetit</a>, Master/Bachelor from Beihang University. Double degree from <a href="https://www.ec-lyon.fr/en">ECLyon</a>.
</p>


<h2>News</h2>
<ul>
	<li>
        [03/2024] Joined Meta GenAI as a Research Scientist(Zürich).</b>
	</li>
	<li>
        [03/2023] Finished my internship at Meta(London).</b>
	</li>
	<li>
        [01/2022] Finished my internship at Naver Labs Europe(Grenoble).</b>
	</li>
</ul>



<h2> Publications [<a href="https://scholar.google.com/citations?user=mLytdOoAAAAJ&hl=en">Google Scholar</a>]</h2>
<table id="tbPublications" width="100%" style="border-collapse:separate; border-spacing:0px 10px;">
<h3> (* indicates equal contribution) </h3>
	<tbody>

	<tr>
		<td><center><img width="250" src="./pic/papers/ard.png"></center></td>
		<td>
			<font size="2">Autoregressive Distillation of Diffusion Transformers
			<br>
			<i>Yeongmin Kim, Sotiris Anagnostidis, <b>Yuming Du</b>, Edgar Schönfeld, Jonas Kohler, Markos Georgopoulos, Albert Pumarola, Ali Thabet, Artsiom Sanakoyeu</i>
			<br>
			<b>CVPR</b> 2025(<b>Oral</b>)
			<br>
                        [<a href='https://arxiv.org/abs/2504.11295'><b>paper</b></a>]
		</td>
	</tr>
	
	<tr>
		<td><center><img width="250" src="./pic/papers/flexdit.png"></center></td>
		<td>
			<font size="2">FlexiDiT: Your Diffusion Transformer Can Easily Generate High-Quality Samples with Less Compute
			<br>
			<i>Sotiris Anagnostidis, Gregor Bachmann, Yeongmin Kim, Jonas Kohler, Markos Georgopoulos, Artsiom Sanakoyeu, <b>Yuming Du</b>, Albert Pumarola, Ali Thabet, Edgar Schönfeld</i>
			<br>
			<b>CVPR</b> 2025(<b>Highlight</b>)
			<br>
                        [<a href='https://arxiv.org/abs/2502.20126'><b>paper</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/judge.png"></center></td>
		<td>
			<font size="2">Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment
			<br>
			<i>Gregor Bachmann, Sotiris Anagnostidis, Albert Pumarola, Markos Georgopoulos, Artsiom Sanakoyeu, <b>Yuming Du</b>, Edgar Schönfeld, Ali Thabet, Jonas Kohler</i>
			<br>
			<b>ICLR</b> 2025(<b>Oral</b>)
			<br>
                        [<a href='https://arxiv.org/abs/2501.19309'><b>paper</b></a>]
		</td>
	</tr>
		
	<tr>
		<td><center><img width="250" src="./pic/papers/moviegen.png"></center></td>
		<td>
			<font size="2">Movie Gen: A Cast of Media Foundation Models
			<br>
			<i>MovieGen team</i>
			<br>
			<b>Arxiv</b> 2024
			<br>
                        [<a href='https://arxiv.org/abs/2410.13720'><b>paper</b></a>|<b>code</b></a>]
		</td>
	</tr>
		
	<tr>
		<td><center><img width="250" src="./pic/papers/agrol.png"></center></td>
		<td>
			<font size="2">Avatars Grow Legs: Generating Smooth Human Motion from Sparse Tracking Inputs with Diffusion Model
			<br>
            <i><b>Yuming Du</b>, Robin Kips, Albert Pumarola, Sebastian Starke, Ali Thabet, Artsiom Sanakoyeu </i>
			<br>
                        <b>CVPR</b> 2023
			<br>
			[<a href='https://arxiv.org/abs/2304.08577'><b>paper</b></a>|<a href='https://github.com/facebookresearch/AGRoL'><b>code</b></a>|<a href='https://dulucas.github.io/agrol/'><b>project page</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/simlpe.png"></center></td>
		<td>
			<font size="2">Back to MLP: A Simple Baseline for Human Motion Prediction
			<br>
			<i>Wen Guo*, <b>Yuming Du*</b>, Xi Shen, Vincent Lepetit, Xavier Alameda-Pineda, Francesc Moreno-Noguer</i>
			<br>
			<b>WACV</b> 2023
			<br>
			[<a href='https://arxiv.org/abs/2207.01567'><b>paper</b></a>|<a href='https://github.com/dulucas/siMLPe'><b>code</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/grasplikehuman.png"></center></td>
		<td>
			<font size="2">Multi-Finger Grasping Like Humans
			<br>
			<i><b>Yuming Du</b>, Philippe Weinzaepfel, Vincent Lepetit, Romain Brégier</i>
			<br>
			<b>IROS</b> 2022
			<br>
                        [<a href='https://arxiv.org/abs/2211.07304'><b>paper</b></a>|<b>code</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/gbopt.png"></center></td>
		<td>
			<font size="2">Learning to Better Segment Objects from Unseen Classes with Unlabeled Videos
			<br>
			<i><b>Yuming Du</b>, Yang Xiao, Vincent Lepetit</i>
			<br>
			<b>ICCV</b> 2021
			<br>
			[<a href='https://arxiv.org/abs/2104.12276'><b>paper</b></a>|<a href='https://dulucas.github.io/gbopt/'><b>project page</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/depthdisp.png"></center></td>
		<td>
			<font size="2">Predicting Sharp and Accurate Occlusion Boundaries in Monocular Depth Estimation Using Displacement Fields
			<br>
			<i>Michael Ramamonjisoa*, <b>Yuming Du*</b>, Vincent Lepetit</i>
			<br>
			<b>CVPR</b> 2020
			<br>
			[<a href='https://arxiv.org/abs/2002.12730'><b>paper</b></a>|<a href='https://github.com/dulucas/Displacement_Field'><b>code</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/uvo.png"></center></td>
		<td>
			<font size="2">1st Place UVO Open-World Segmentation Challenge Reports
			<br>
            <i><b>Yuming Du</b>, Wen Guo, Yang Xiao, Vincent Lepetit</i>
			<br>
            Tech Reports of ICCV 2021 UVO Challenge
			<br>
			[<a href='https://arxiv.org/abs/2110.10239'><b>Image-track</b></a>|<a href='https://arxiv.org/abs/2110.11661'><b>Video-track</b></a>]
		</td>
	</tr>
	
	<tr>
		<td><center><img width="250" src="./pic/papers/tokencut.png"></center></td>
		<td>
			<font size="2">TokenCut: Segmenting Objects in Images and Videos with Self-supervised Transformer and Normalized Cut
			<br>
			<i>Yangtao Wang, Xi Shen, Yuan Yuan, <b>Yuming Du</b>, Maomao Li, Shell Xu Hu, James L Crowley, Dominique Vaufreydaz</i>
			<br>
			<b>TPAMI</b> 2024
			<br>
			[<a href='https://arxiv.org/abs/2209.00383'><b>paper</b></a>|<a href='https://github.com/YangtaoWANG95/TokenCut_video'><b>code</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/pizza.png"></center></td>
		<td>
			<font size="2">PIZZA: A Powerful Image-only Zero-Shot Zero-CAD Approach to 6DoF Tracking
			<br>
            <i>Van Nguyen Nguyen*, <b>Yuming Du*</b>, Yang Xiao, Michael Ramamonjisoa, Vincent Lepetit </i>
			<br>
                        <b>3DV</b> 2022 (<b>Oral</b>)
			<br>
			[<a href='https://arxiv.org/abs/2209.07589'><b>paper</b></a>|<a href='https://github.com/nv-nguyen/pizza'><b>code</b></a>]
		</td>
	</tr>
		
	<tr>
		<td><center><img width="250" src="./pic/papers/simdisco.jpeg"></center></td>
		<td>
			<font size="2">A Simple and Powerful Global Optimization for Unsupervised Video Object Segmentation	
			<br>
			<i>Georgy Ponimatkin, Nermin Samet, Yang Xiao, <b>Yuming Du</b>, Renaud Marlet, Vincent Lepetit</i>
			<br>
			<b>WACV</b> 2023
			<br>
			[<a href='https://arxiv.org/abs/2209.09341'><b>paper</b></a>|<a href='https://github.com/ponimatkin/ssl-vos'><b>code</b></a>]
		</td>
	</tr>
		
	<tr>
		<td><center><img width="250" src="./pic/papers/posconst.png"></center></td>
		<td>
			<font size="2">PoseContrast: Class-Agnostic Object Viewpoint Estimation in the Wild with Pose-Aware Contrastive Learning
			<br>
			<i>Yang Xiao, <b>Yuming Du</b>, Renaud Marlet</i>
			<br>
			<b>3DV</b> 2021 (<b>Oral</b>)
			<br>
			[<a href='https://arxiv.org/abs/2105.05643'><b>paper</b></a>|<a href='http://imagine.enpc.fr/~xiaoy/PoseContrast/'><b>code</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/sbpose.png"></center></td>
		<td>
			<font size="2">Rethinking on Multi-stage Networks for Human Pose Estimation
			<br>
            <i>Wenbo Li, Zhicheng Wang, Binyi Yin, Qixiang Peng, <b>Yuming Du</b>, Tianzi Xiao, Gang Yu, Hongtao Lu, Yichen Wei, Jian Sun</i>
			<br>
            Champion of ECCV 2018 COCO Keypoint Detection Challenge
			<br>
			[<a href='https://arxiv.org/abs/1901.00148'><b>paper</b></a>|<a href='https://github.com/megvii-research/MSPN'><b>code</b></a>]
		</td>
	</tr>
		
    </tbody>
</table>


<h2><font> Honors and Awards </font></h2>
<ul>
<!--<ul style="list-style-type:none">
<p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">-->
    <li>
		Champion of ICCV 2021 UVO Open-World Segmentation Challenge 2021 on both Image-/Video-track
    </li>
    <li>
		Champion of ECCV 2018 COCO Keypoint Detection Challenge
    </li>
</ul>

<h2><font> Academic Service </font></h2>
<ul>
    <b>Journal/Conference Review:</b></br>
    TPAMI, IJCV, CVPR, ECCV, ISMAR, WACV, BMVC</br>
</ul>


<p><center><font>
        <br>&copy; Yuming Du | Last updated: May. 2025 | <a href="photography/index.html">.</a> </font></center>
</p>

</div>
</body></html>
